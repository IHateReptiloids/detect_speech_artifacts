{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "x21r4quk3gcf8hsr5mt6nc"
   },
   "source": [
    "## Generate train-val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "th43q7u6caqerisb23bqyp"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "tm0iwoy5vd8w89sh66tvcp"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "TRAIN_FRAC = 0.9\n",
    "\n",
    "rng = np.random.default_rng(8228)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "aka3d3uhlwm1zkzcy6tq8b"
   },
   "outputs": [],
   "source": [
    "ds = pd.read_csv('data/ssp/all_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "dtpm5e97m447689gilzq"
   },
   "outputs": [],
   "source": [
    "p = rng.permutation(len(ds))\n",
    "train_ds = ds.iloc[p[:int(TRAIN_FRAC * len(ds))]]\n",
    "val_ds = ds.iloc[p[int(TRAIN_FRAC * len(ds)):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "0eklecbbbuml4ev47t0raz3"
   },
   "outputs": [],
   "source": [
    "train_ds.to_csv('data/ssp/train_labels.csv', index=False, quoting=csv.QUOTE_ALL)\n",
    "val_ds.to_csv('data/ssp/val_labels.csv', index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "n9day8x57m71ydx44rmnh"
   },
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "gzeqp9g91zprboulest9b"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "776qkh7lk6vgi6z1wrcgpv"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from src.datasets import MultiLabelClassificationCollator, SSPNetVC\n",
    "from src.models import PretrainedPaSST\n",
    "from src.trainers import MultiLabelClassificationTrainer\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_AUDIOSET_CLASSES = 527\n",
    "THRESHOLD = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "bkrn0m54idct7so4pco1"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "labels_df = pd.read_csv('data/audioset/class_labels_indices.csv')\n",
    "label2ind = dict(zip(labels_df['display_name'], labels_df['index']))\n",
    "assert len(label2ind) == NUM_AUDIOSET_CLASSES\n",
    "label2ind['Filler'] = NUM_AUDIOSET_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellId": "tgk2m6e188o2putyj5x2vx"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "train_ds = SSPNetVC(csv=Path('data/ssp/train_labels.csv'))\n",
    "val_ds = SSPNetVC(csv=Path('data/ssp/val_labels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "gnaoy7n1dkde9r9knwmca"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "collator = MultiLabelClassificationCollator(label2ind)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, BATCH_SIZE,\n",
    "                                           shuffle=True, collate_fn=collator,\n",
    "                                           pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, BATCH_SIZE,\n",
    "                                           shuffle=True, collate_fn=collator,\n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellId": "v39h7wzsx8nqaa8m263jtf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/kkoutini/PaSST/releases/download/v0.0.1-audioset/passt-s-f128-p16-s10-ap.476-swa.pt\" to /tmp/xdg_cache/torch/hub/checkpoints/passt-s-f128-p16-s10-ap.476-swa.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: FMAX is None setting to 15000 \n",
      "\n",
      "\n",
      " Loading PASST TRAINED ON AUDISET \n",
      "\n",
      "\n",
      "PaSST(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (pre_logits): Identity()\n",
      "  (head): Sequential(\n",
      "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=768, out_features=527, bias=True)\n",
      "  )\n",
      "  (head_dist): Linear(in_features=768, out_features=527, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model = PretrainedPaSST(num_new_classes=1, max_audio_len=11.0).to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "trainer = MultiLabelClassificationTrainer(model, opt, train_loader, val_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellId": "zikm8wrcx8h6v6olzwlf82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/311 [00:00<?, ?it/s]/home/jupyter/.local/lib/python3.8/site-packages/torch/functional.py:572: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at  ../aten/src/ATen/native/SpectralOps.cpp:659.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "100%|██████████| 311/311 [03:19<00:00,  1.56it/s]\n",
      "100%|██████████| 35/35 [00:09<00:00,  3.78it/s]\n",
      "100%|██████████| 311/311 [03:19<00:00,  1.56it/s]\n",
      "100%|██████████| 35/35 [00:09<00:00,  3.78it/s]\n",
      "100%|██████████| 311/311 [03:20<00:00,  1.55it/s]\n",
      "100%|██████████| 35/35 [00:09<00:00,  3.77it/s]\n",
      "100%|██████████| 311/311 [03:20<00:00,  1.55it/s]\n",
      "100%|██████████| 35/35 [00:09<00:00,  3.78it/s]\n",
      "100%|██████████| 311/311 [03:20<00:00,  1.55it/s]\n",
      "100%|██████████| 35/35 [00:09<00:00,  3.78it/s]\n",
      "100%|██████████| 311/311 [03:20<00:00,  1.55it/s]\n",
      "100%|██████████| 35/35 [00:09<00:00,  3.77it/s]\n",
      "100%|██████████| 311/311 [03:20<00:00,  1.55it/s]\n",
      "100%|██████████| 35/35 [00:09<00:00,  3.78it/s]\n",
      "100%|██████████| 311/311 [03:20<00:00,  1.55it/s]\n",
      "100%|██████████| 35/35 [00:09<00:00,  3.77it/s]\n",
      "100%|██████████| 311/311 [03:20<00:00,  1.55it/s]\n",
      "100%|██████████| 35/35 [00:09<00:00,  3.78it/s]\n",
      "100%|██████████| 311/311 [03:20<00:00,  1.55it/s]\n",
      "100%|██████████| 35/35 [00:09<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 1:\n",
      "x torch.Size([8, 1, 128, 1100])\n",
      "self.norm(x) torch.Size([8, 768, 12, 109])\n",
      " patch_embed :  torch.Size([8, 768, 12, 109])\n",
      " self.time_new_pos_embed.shape torch.Size([1, 768, 1, 1100])\n",
      " CUT time_new_pos_embed.shape torch.Size([1, 768, 1, 109])\n",
      " self.freq_new_pos_embed.shape torch.Size([1, 768, 12, 1])\n",
      "X flattened torch.Size([8, 1308, 768])\n",
      " self.new_pos_embed.shape torch.Size([1, 2, 768])\n",
      " self.cls_tokens.shape torch.Size([8, 1, 768])\n",
      " self.dist_token.shape torch.Size([8, 1, 768])\n",
      " final sequence x torch.Size([8, 1310, 768])\n",
      " after 12 atten blocks x torch.Size([8, 1310, 768])\n",
      "forward_features torch.Size([8, 768])\n",
      "head torch.Size([8, 528])\n",
      "Train loss: tensor(0.0086, device='cuda:0')\n",
      "Train mAP: tensor(0.8558, device='cuda:0')\n",
      "Validation loss: tensor(0.0065, device='cuda:0')\n",
      "Validation mAP: tensor(0.9014, device='cuda:0')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 2\n",
      "Epoch 1:\n",
      "Train loss: tensor(0.0070, device='cuda:0')\n",
      "Train mAP: tensor(0.8903, device='cuda:0')\n",
      "Validation loss: tensor(0.0063, device='cuda:0')\n",
      "Validation mAP: tensor(0.9110, device='cuda:0')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 3\n",
      "Epoch 1:\n",
      "Train loss: tensor(0.0068, device='cuda:0')\n",
      "Train mAP: tensor(0.8980, device='cuda:0')\n",
      "Validation loss: tensor(0.0061, device='cuda:0')\n",
      "Validation mAP: tensor(0.9149, device='cuda:0')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 4\n",
      "Epoch 1:\n",
      "Train loss: tensor(0.0066, device='cuda:0')\n",
      "Train mAP: tensor(0.9025, device='cuda:0')\n",
      "Validation loss: tensor(0.0059, device='cuda:0')\n",
      "Validation mAP: tensor(0.9210, device='cuda:0')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 5\n",
      "Epoch 1:\n",
      "Train loss: tensor(0.0063, device='cuda:0')\n",
      "Train mAP: tensor(0.9082, device='cuda:0')\n",
      "Validation loss: tensor(0.0058, device='cuda:0')\n",
      "Validation mAP: tensor(0.9215, device='cuda:0')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 6\n",
      "Epoch 1:\n",
      "Train loss: tensor(0.0063, device='cuda:0')\n",
      "Train mAP: tensor(0.9088, device='cuda:0')\n",
      "Validation loss: tensor(0.0057, device='cuda:0')\n",
      "Validation mAP: tensor(0.9235, device='cuda:0')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 7\n",
      "Epoch 1:\n",
      "Train loss: tensor(0.0061, device='cuda:0')\n",
      "Train mAP: tensor(0.9134, device='cuda:0')\n",
      "Validation loss: tensor(0.0056, device='cuda:0')\n",
      "Validation mAP: tensor(0.9247, device='cuda:0')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 8\n",
      "Epoch 1:\n",
      "Train loss: tensor(0.0061, device='cuda:0')\n",
      "Train mAP: tensor(0.9135, device='cuda:0')\n",
      "Validation loss: tensor(0.0056, device='cuda:0')\n",
      "Validation mAP: tensor(0.9268, device='cuda:0')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 9\n",
      "Epoch 1:\n",
      "Train loss: tensor(0.0060, device='cuda:0')\n",
      "Train mAP: tensor(0.9182, device='cuda:0')\n",
      "Validation loss: tensor(0.0055, device='cuda:0')\n",
      "Validation mAP: tensor(0.9285, device='cuda:0')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 10\n",
      "Epoch 1:\n",
      "Train loss: tensor(0.0059, device='cuda:0')\n",
      "Train mAP: tensor(0.9180, device='cuda:0')\n",
      "Validation loss: tensor(0.0054, device='cuda:0')\n",
      "Validation mAP: tensor(0.9280, device='cuda:0')\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "warnings.filterwarnings('ignore', 'Input image size', UserWarning)\n",
    "for i in range(10):\n",
    "    print('Epoch', i + 1)\n",
    "    trainer.train_loop(1)\n",
    "    torch.save(trainer.model, f'checkpoint{i}.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2a8dcf37b444d40f84861cd5168550f60f0c48261e12dba12aa8393f0a007ce"
  },
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "notebookId": "dd1a477f-66dd-453e-ac41-fdca5a6927de",
  "notebookPath": "PaSST/passt_ssp_finetuning.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
